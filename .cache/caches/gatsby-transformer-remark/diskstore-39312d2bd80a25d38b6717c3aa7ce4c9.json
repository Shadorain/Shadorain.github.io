{"expireTime":9007200850472567000,"key":"transformer-remark-markdown-html-3c18434102526c001a51b0d5d1485224-gatsby-remark-codefencegatsby-remark-katexgatsby-remark-prismjsgatsby-remark-embed-youtube-","val":"<h2>What is Deepspeech</h2>\n<p>From Mozilla's github repo for deepspeech:</p>\n<p>\"DeepSpeech is an open source Speech-To-Text engine, using a model trained by machine learning techniques based on Baidu's Deep Speech research paper. Project DeepSpeech uses Google's TensorFlow to make the implementation easier.\"</p>\n<h2>Virtual environment</h2>\n<p>First let's create a virtual environment for deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      conda create -n ds python=3.8\n\nconda activate deepspeech\n    </textarea>\n    </code-fence>\n  \n<h2>Install deepspeech</h2>\n<p>The only required package is deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      pip install deepspeech\n    </textarea>\n    </code-fence>\n  \n<h1>Download Model</h1>\n<p>A pre-trained english model is available for download</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n\ntar xvf deepspeech-0.6.1-models.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Download audio files</h1>\n<p>You can download some example audio files</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/audio-0.6.1.tar.gz\n\ntar xvf audio-0.6.1.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Run inference</h1>\n<p>We can now transcribe the audio file</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio audio/2830-3980-0043.wav\n    </textarea>\n    </code-fence>\n  \n<p>If you ran the above command you should see something like \"experience proofsless\" if you are using the same model as me</p>\n<p>So not perfect, but we can try it out on our own voice as well</p>\n<h1>Record a wav file</h1>\n<p>For deepspeech to run inference correctly you will need to record your voice with some specific parameters.</p>\n<ul>\n<li>Sampling rate: 16 kHz</li>\n<li>Channel: 1</li>\n<li>Bit rate: 256 kb/s</li>\n</ul>\n<p>We can achieve this using the <code class=\"language-text\">sox</code> package</p>\n<p>If you're on Ubuntu:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      sudo apt install sox\n    </textarea>\n    </code-fence>\n  \n<p>Arch Linux:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      yay -S sox\n    </textarea>\n    </code-fence>\n  \n<p>Mac:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      brew install sox\n    </textarea>\n    </code-fence>\n  \n<p>After installing <code class=\"language-text\">sox</code> you should have access to the <code class=\"language-text\">rec</code> command, we will use this to record our voice</p>\n<p>To begin recording you voice enter the following command</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      rec -r 16k -c 1 my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>To make sure you have recorded the audio in the proper format we can install another package called <code class=\"language-text\">mediainfo</code> and run it like so:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      mediainfo my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>You should see an output similar to the following:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      General\nComplete name                            : my_recording.wav\nFormat                                   : Wave\nFile size                                : 64.0 KiB\nDuration                                 : 2 s 48 ms\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 256 kb/s\n\nAudio\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 2 s 48 ms\nBit rate mode                            : Constant\nBit rate                                 : 256 kb/s\nChannel(s)                               : 1 channel\nSampling rate                            : 16.0 kHz\nBit depth                                : 16 bits\nStream size                              : 64.0 KiB (100%)\n    </textarea>\n    </code-fence>\n  \n<h2>Run inference</h2>\n<p>Now we can run inference on our own voice data</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<h2>Wrapping up</h2>\n<p>In the next article I'll go over running inference on a GPU</p>"}