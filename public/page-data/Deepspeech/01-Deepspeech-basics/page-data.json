{"componentChunkName":"component---src-templates-blog-post-js","path":"/Deepspeech/01-Deepspeech-basics/","result":{"data":{"markdownRemark":{"id":"7c137ed9-ee48-58ec-8fb2-0d6af5bb4112","html":"<h2>What is Deepspeech</h2>\n<p>From Mozilla's github repo for deepspeech:</p>\n<p>\"DeepSpeech is an open source Speech-To-Text engine, using a model trained by machine learning techniques based on Baidu's Deep Speech research paper. Project DeepSpeech uses Google's TensorFlow to make the implementation easier.\"</p>\n<h2>Virtual environment</h2>\n<p>First let's create a virtual environment for deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      conda create -n ds python=3.8\n\nconda activate deepspeech\n    </textarea>\n    </code-fence>\n  \n<h2>Install deepspeech</h2>\n<p>The only required package is deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      pip install deepspeech\n    </textarea>\n    </code-fence>\n  \n<h1>Download Model</h1>\n<p>A pre-trained english model is available for download</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n\ntar xvf deepspeech-0.6.1-models.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Download audio files</h1>\n<p>You can download some example audio files</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/audio-0.6.1.tar.gz\n\ntar xvf audio-0.6.1.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Run inference</h1>\n<p>We can now transcribe the audio file</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio audio/2830-3980-0043.wav\n    </textarea>\n    </code-fence>\n  \n<p>If you ran the above command you should see something like \"experience proofsless\" if you are using the same model as me</p>\n<p>So not perfect, but we can try it out on our own voice as well</p>\n<h1>Record a wav file</h1>\n<p>For deepspeech to run inference correctly you will need to record your voice with some specific parameters.</p>\n<ul>\n<li>Sampling rate: 16 kHz</li>\n<li>Channel: 1</li>\n<li>Bit rate: 256 kb/s</li>\n</ul>\n<p>We can achieve this using the <code class=\"language-text\">sox</code> package</p>\n<p>If you're on Ubuntu:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      sudo apt install sox\n    </textarea>\n    </code-fence>\n  \n<p>Arch Linux:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      yay -S sox\n    </textarea>\n    </code-fence>\n  \n<p>Mac:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      brew install sox\n    </textarea>\n    </code-fence>\n  \n<p>After installing <code class=\"language-text\">sox</code> you should have access to the <code class=\"language-text\">rec</code> command, we will use this to record our voice</p>\n<p>To begin recording you voice enter the following command</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      rec -r 16k -c 1 my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>To make sure you have recorded the audio in the proper format we can install another package called <code class=\"language-text\">mediainfo</code> and run it like so:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      mediainfo my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>You should see an output similar to the following:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      General\nComplete name                            : my_recording.wav\nFormat                                   : Wave\nFile size                                : 64.0 KiB\nDuration                                 : 2 s 48 ms\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 256 kb/s\n\nAudio\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 2 s 48 ms\nBit rate mode                            : Constant\nBit rate                                 : 256 kb/s\nChannel(s)                               : 1 channel\nSampling rate                            : 16.0 kHz\nBit depth                                : 16 bits\nStream size                              : 64.0 KiB (100%)\n    </textarea>\n    </code-fence>\n  \n<h2>Run inference</h2>\n<p>Now we can run inference on our own voice data</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<h2>Wrapping up</h2>\n<p>In the next article I'll go over running inference on a GPU</p>","excerpt":"What is Deepspeech From Mozilla's github repo for deepspeech: \"DeepSpeech is an open source Speech-To-Text engine, using a model trained byâ€¦","frontmatter":{"title":"Deepspeech basics","tags":["deepspeech"],"image":{"childImageSharp":{"resize":{"src":"/static/86a12aba2f2bc50aedd3e00976f6edbc/a8734/mozilla-deepspeech.png"},"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAACxKAAAsSgF3enRNAAACXUlEQVQoz2OYMHH7gQPXVq85OWXqrpkz986atS8yaqqkVLaOboWBYZW+AQjpGVQaGtaAGVWOlh0O5q0BTlP8PWYxAHV++PD1zZvPN248e/z4zfPn7/fsuQI0Ijx8soZmmaFRNVCPrn6lh12fi3WXg2VHuNusCOfpXl6zleNXM3R3b9mx89KChYcmTd45e/b+2XP2z5q9b82aU1HR09Q1SoGa9fQrjY3rgpynBbvOCHSbEeQyLdxxsnHYYp6czQxa2uWaWmU6OhVAdwLZQKStU66pXa6jVwnUpqdfoaNX7mDd6eI719N9RoDLNDu/eXb+86RT1vJlb2bQN6g0MW2wt+8FKoX4EIgMgGz9SjOLFgvLVmvbLi/XqYoJqzSjllr5z+XP3syfuYk/Y5NA1iYGPb0KM8tWJ48ZhsZ1IP2G1QZ6FerWLYa2nc5u0508Zzp7zHB0nyGaup4va5NA5kb+9E081Ru4G9YLpG1i0NcrN3fotfaebWbbBbHcUK9CLHy+UvRyO9cp1m5TbTym6kTM40/fyJ+5kS9jo0DKRrap65hWreEt3MBgZNmqGTBHNma5qcc0I6d+E9suA9dJgqlrhVLX6fnNUg1eqJSygLt/FX/qBoGM9fwZ6/ny1zMvXgPUzDprDYOu5wyJmOUCqWu1vWZo+s6Wi1wqG7FUMGWtUPIa4cQ1golrOVvWAlULpq/hqVrDMmct25Q1zAvXsMxfw7xoDYNw6grh5BViMStkQxZKhi8RSlwlkL1KLGa5SOIK/sLVonErODrXssxcx92whr13LfPMdSzT17FOhSIAsNbt18n2CLUAAAAASUVORK5CYII=","aspectRatio":1.9898989898989898,"src":"/static/86a12aba2f2bc50aedd3e00976f6edbc/5134e/mozilla-deepspeech.png","srcSet":"/static/86a12aba2f2bc50aedd3e00976f6edbc/06f82/mozilla-deepspeech.png 197w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/da7d7/mozilla-deepspeech.png 393w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/5134e/mozilla-deepspeech.png 786w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/7a32a/mozilla-deepspeech.png 1179w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/6c0d9/mozilla-deepspeech.png 1572w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/b9295/mozilla-deepspeech.png 3690w","sizes":"(max-width: 786px) 100vw, 786px"}}}}}},"pageContext":{"slug":"/Deepspeech/01-Deepspeech-basics/","prev":{"node":{"fields":{"slug":"/Deepspeech/02-Deepspeech-gpu/"},"frontmatter":{"title":"Deepspeech using a GPU","tags":["deepspeech"]}}},"next":{"node":{"fields":{"slug":"/Linux/02-Create-User/"},"frontmatter":{"title":"Creating users","tags":["linux"]}}}}}}